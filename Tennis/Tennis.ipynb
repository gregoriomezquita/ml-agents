{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis: Collaboration and Competition\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Setting the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "aws_unity_filename= './Tennis_Linux_NoVis/Tennis.x86_64'\n",
    "laptop_unity_filename= './Tennis_Linux/Tennis.x86_64'\n",
    "seed= 0 #datetime.now().second\n",
    "env = UnityEnvironment(seed= seed, file_name= laptop_unity_filename)\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "#Handy functions to help understand the code\n",
    "def env_reset(env, train=True):\n",
    "    env_info = env.reset(train_mode= train)[env.brain_names[0]]\n",
    "    return env_info.vector_observations, len(env_info.agents)\n",
    "\n",
    "def env_step(env, action):\n",
    "    env_info= env.step(action)[env.brain_names[0]]\n",
    "    return env_info.vector_observations, env_info.rewards, env_info.local_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Agents definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from glob import glob\n",
    "import re\n",
    "import math\n",
    "\n",
    "from ddpg import DDPG\n",
    "\n",
    "class Agents:\n",
    "    def __init__(self, num_agents=1, config= None):\n",
    "        if not config: \n",
    "            raise OSError('DDPG: no configuration parameter in class init')\n",
    "        self.config= config\n",
    "        self.num_agents= num_agents\n",
    "        self.agents= []\n",
    "        self.scores= []\n",
    "        for i in range(num_agents):\n",
    "            self.agents.append( DDPG(config= config) )\n",
    "    \n",
    "    def reset(self):\n",
    "        for agent in self.agents: \n",
    "            agent.reset()\n",
    "            \n",
    "    def act(self, states, train= True):\n",
    "        actions= np.array([])\n",
    "        for i, agent in zip(range(self.num_agents), self.agents):\n",
    "            actions= np.append(actions, agent.act( states[i], train ) )\n",
    "        return actions\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # states and action are numpy arrays while reward and done are lists\n",
    "        # Single experience replay\n",
    "        \"\"\"\n",
    "        for i, agent in zip(range(self.num_agents), self.agents):\n",
    "            action_size= agent.action_size\n",
    "            agent.step(state[i], action[action_size*i:(action_size*i)+action_size], reward[i], next_state[i], done[i])\n",
    "        \"\"\"\n",
    "        # Combined experience replay\n",
    "        for agent in self.agents:\n",
    "            for i in range(self.num_agents):\n",
    "                s= slice(agent.action_size*i, (agent.action_size*i)+ agent.action_size)\n",
    "                agent.memory.add(state[i], action[s], reward[i], next_state[i], done[i])\n",
    "            if len(agent.memory) >= agent.batch_size:\n",
    "                agent.learn()\n",
    "            \n",
    "    def update(self, score):\n",
    "        self.scores.append(score)\n",
    "        if (len(self.scores)> 0) and (score > np.max(self.scores)):    # Save actors for best score\n",
    "            for i, agent in zip(range(self.num_agents), self.agents):\n",
    "                torch.save(agent.actor.state_dict(), \"last_actor_{}.pth\".format(i+ 1))\n",
    "        \"\"\"\n",
    "        # Update agent\n",
    "        if not self.config[\"param_noise\"]: return 0.0\n",
    "        dists= []\n",
    "        for agent in self.agents:\n",
    "            #agent.update()\n",
    "            #states, perturbed_actions= agent.action_memory.pop()\n",
    "            states, perturbed_actions, _, _, _= agent.memory.sample(1024)\n",
    "            #states, perturbed_actions, _, _, _= agent.memory.get(agent.steps * self.num_agents)\n",
    "            #states, perturbed_actions, _, _, _= agent.memory.get(1024)\n",
    "            unperturbed_actions = agent.act(states, False)\n",
    "            ddpg_dist = agent.param_noise.distance(perturbed_actions.numpy(), unperturbed_actions)\n",
    "            \n",
    "            agent.param_noise.adapt(ddpg_dist)\n",
    "            dists.append(ddpg_dist)\n",
    "            \n",
    "        return np.mean(dists)\n",
    "        \"\"\"\n",
    "                                      \n",
    "    def save(self):\n",
    "        data= {\"config\": self.config, \"scores\": self.scores,}\n",
    "        fname= \"./{}_\".format(self.__class__.__name__)\n",
    "        last_index= 1\n",
    "        files= sorted(glob(\"{}*.data\".format(fname)))\n",
    "        if files:\n",
    "            last= files[-1]\n",
    "            if last: \n",
    "                last_index= int(re.findall('[0-9]+', last, flags=re.IGNORECASE)[0])\n",
    "                last_index+= 1\n",
    "        filename= \"{}{}.data\".format(fname, last_index)\n",
    "        torch.save(data, filename)\n",
    "        # Last actor for all agents\n",
    "        for i, agent in zip(range(self.num_agents), self.agents):\n",
    "            torch.save(agent.actor.state_dict(), \"last_actor_{}.pth\".format(i+ 1))\n",
    "            \n",
    "    def load(self):\n",
    "        for i, agent in zip(range(self.num_agents), self.agents):\n",
    "            model= torch.load(\"last_actor_{}.pth\".format(i+ 1), map_location=lambda storage, loc: storage)\n",
    "            agent.actor.load_state_dict(model)\n",
    "        \n",
    "    def eval(self):\n",
    "        for agent in self.agents:\n",
    "            agent.actor.eval() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.04   \n",
      "Episode 200\tAverage Score: 0.03   \n",
      "Episode 300\tAverage Score: 0.04   \n",
      "Episode 400\tAverage Score: 0.07   \n",
      "Episode 500\tAverage Score: 0.11   \n",
      "Episode 576\tAverage Score: 0.50   \n",
      "Environment solved in 476 episodes!\tAverage Score: 0.50\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8XHd96P3Pdzbt+2LJlm15i5fYcZyYLE0IhhRIKCVtoeyF8rQ3lz5wL+2LPi3Q+6Itz3Kf23tve+EJF0pZWpYX9DZQCDQBAoRsZLGd2JbXxLYsS7b2XRpJs32fP86Z8WgZaSRrNDPS9/166aWZc86c8z2jo/M9v+X8jqgqxhhjzFw82Q7AGGNM7rIkYYwxJiVLEsYYY1KyJGGMMSYlSxLGGGNSsiRhjDEmJUsSxhhjUrIkYYwxJiVLEsYYY1LyZTuAxaqtrdXm5uZsh2GMMXnl6NGjfapat9jP5V2SaG5u5siRI9kOwxhj8oqItC3lc1bdZIwxJiVLEsYYY1KyJGGMMSYlSxLGGGNSsiRhjDEmJUsSxhhjUrIkYYwxJiVLEsYYk+N6e3sJhUJZ2bYlCWOMyWGRSIRTp07R0tKSle1bkjDGmBwWiUQACAaDWdm+JQljjMlh4XA4q9u3JGGMMTksXpLIFksSxhiTw6wkYYwxJqVsJ4m8GyrcGGNWg1gsRiwWw+fzoapEIhE8Hg+xWIxIJILP55yes13dZEnCGGOy4OWXX2Z0dJRDhw5x8eJF2tvb51zO43EqfKLRKKqKiKxkmFbdZIwx2TA6Opp43dXVlXK5WCy2EuGkZEnCGGOyLNuJYD6WJIwxJsvWZJIQkY0i8oSInBaRUyLysTmWOSQiwyJyzP35dKbiMcaYXKWq2Q4hpUw2XEeAj6vqSyJSBhwVkcdV9fSM5Z5W1bdmMA5jjFkVVlXDtap2qupL7utR4AywIVPbM8YYs/xWpE1CRJqBA8ALc8y+U0SOi8hjInLjSsRjjDEmPRm/T0JESoHvAn+sqiMzZr8EbFbVMRF5C/B9YMcc63gQeBBg06ZNGY7YGGNWTi63R0CGSxIi4sdJEN9S1e/NnK+qI6o65r5+FPCLSO0cy31JVQ+q6sG6urpMhmyMMSZJJns3CfAV4Iyq/m2KZRrc5RCR29x4+jMVkzHG5JrFlCSyUerIZHXTXcDvAS0icsyd9ilgE4CqfhF4B/BHIhIBJoB3a66XvYwxZhnl+ikvY0lCVZ8B5u2rpaoPAQ9lKgZjjMl1uZ4k7I5rY4zJIksSxhhjUrIkYYwxJiVLEsYYY1LK9d5NliSMMSaLrCRhjDEmJUsSxhhjUrIkYYwxJm9ZkjDGmCyyhmtjjDGzxB8eZNVNxhhjZokniVx+vjVYkjDGmKyykoQxxphZrLrJGGNMSktJEtZwbYwxa4SVJIwxxizIGq6NMcbMYiUJY4wxKVmSMMYYk5I1XBtjjFmQlSSMMcbMYndcG2OMScnaJIwxxizIkoQxxphZrOHaGGNMSlbdZIwxZkGWJIwxxuQtSxLGGJNFa7YkISIbReQJETktIqdE5GNzLCMi8jkROS8iJ0TklkzFY4wxZvF8GVx3BPi4qr4kImXAURF5XFVPJy1zP7DD/bkd+IL72xhj1oQ127tJVTtV9SX39ShwBtgwY7EHgK+r43mgUkQaMxWTMcaYxVmRNgkRaQYOAC/MmLUBaE9638HsRIKIPCgiR0TkSG9vb6bCNMaYFbdm2yTiRKQU+C7wx6o6spR1qOqXVPWgqh6sq6tb3gCNMcaklNEkISJ+nATxLVX93hyLXAE2Jr1vcqcZY8yasGZLEuLcTvgV4Iyq/m2KxR4BPuD2croDGFbVzkzFZIwxuWZmkjjfM8ZTr/QSjs4eHTYbCSWTvZvuAn4PaBGRY+60TwGbAFT1i8CjwFuA80AQ+FAG4zHGmJz32MlOojFla10JTVXF2Q4nc0lCVZ8BZIFlFPhIpmIwxphclWrspmjMeR+J5UY1lN1xbYwxOSgatSRhjDFrXqp2BitJGGOMSSk6R5JYVXdcG2OMWViqE/9cSSIbLEkYY0wOisRmd4HNBksSxhiTRcklieTXVpIwxhgzTXJesCRhjDFmWukhlvR6rt5N1nBtjDE5orOzk/Hx8RXdZnLpwUoSxhiTw86dO8fhw4czvp1U7RCWJIwxxkxLEhFLEsYYY1JJTgzWBdYYY8yiqpus4doYY9aIuU741iZhjDFmmmkliQW6wGaDJQljjMkRMTcxiOROSSKTT6YzxhizgLl6N+1vqmRdeWG2QprGkoQxxuSIF1v7AdjTWE59jiQJq24yxpgZVrIXUfK2hiciAFSXBhZcdqVYkjDGmCyYecJXVSbDUQ42V+Pz5M6p2aqbjDEmi1SVUCRGNKbEVCn2e7Md0jSWJIwxJsv+5y/P0+C2QRQFcitJ5E6ZxhhjcsRK1v3H3OE3ukYmASjMsZKEJQljjMmiUGT6GE3F85QkrOHaGGPWiPgJPxSdniSsJGGMMTluJa/YZ5Yk/F5ZsW2nY96GaxFpAVJ+W6p607JHZIwxa0h4Rkkil7q/wsK9m97q/v6I+/sb7u/3LbRiEfmq+/keVd07x/xDwA+AVnfS91T1Mwut1xhjVpNQJDrtvc+TRyUJVW0DEJE3quqBpFmfEJGXgE/M8/F/BB4Cvj7PMk+r6lvnmW+MMatacnWT1yN45kkSudxwLSJyV9KbX1vos6r6FDBwHbEZY0xWrMTJOL6N5OqmXCtFQPo30/1vwNdEpMJ9P+ROu153ishx4Crwp6p6ahnWaYwxeSO5usmbY+0RkEaSEBEPsF1V98eThKoOL8O2XwI2q+qYiLwF+D6wI0UMDwIPAmzatGkZNm2MMbkhnFTdlGs9myCN6iZVjQF/5r4eXqYEgaqOqOqY+/pRwC8itSmW/ZKqHlTVg3V1dcuxeWOMyQmhHK9uSrds8zMR+VMR2Sgi1fGf69mwiDSIiLivb3Nj6b+edRpjzHJYyQbiyLQkMf8pORsN1+m2SbzL/f2RpGkKbE31ARH5NnAIqBWRDuAvAT+Aqn4ReAfwRyISASaAd2s2vgFjjMmiqaTqJl8OVjellSRUdctiV6yq71lg/kM4XWSNMWbNiV8TDwdDiWm5WN2U9lDhIrIX2AMknqmnqvPdA2GMMXlpJSs1BseTkoQ3D3s3AYjIX+JUHe0BHgXuB55h/hvljDHGLKA/KUl4JfdKEummrXcA9wJdqvohYD9QMf9HjDHGzCcaU4KhCIF4CWKBHJHLd1xPuF1hIyJSDvQAGzMXljHGrG4x97GlAE1VRZQW+NhcXZzlqGZLt03iiIhUAv8AHAXGgOcyFpUxxmTRSlyxf+uFNq70jSB42Fxbwttu3pDxbS5Fur2b/nf35RdF5MdAuaqeyFxYxhizurX2jhNwq5dysVdTXLoN198AnsIZtfVsZkMyxpi1xZvDSSLdNomvAo3A/yciF0XkuyLysQzGZYwxq1q8I5OQfkkiZ++4VtUnROQp4DXA64EPAzcCn81gbMYYkxUrezLWnBz9NS7d6qafAyU4jdVPA69R1Z5MBmaMMWuBsDqqm04AIWAvcBOwV0SKMhaVMcasIXnfcK2qfwIgImXA7wNfAxqAgoxFZowxWbLSdf+5XJJIt7rpo8BrgVuBSzgN2U9nLixjjFndJOl33icJnEH9/hY4qqqRDMZjjDFrjOZ076a02iRU9b/hPAvi9wBEpE5EFj18uDHGmNlyuSSRVpJwR4H9c+CT7iQ/8M1MBWWMMdm00lfsCz2RLpvSjey3gbcB4wCqehUoy1RQxhiTj2KxGOfPnycSWVytfN6XJICQ+2hRBRCRksyFZIwx+am7u5uOjg4uXrw473IzSyqrIUn8LxH5e6BSRP4d8DPgy5kLyxhj8k/85L9QdVUklrjmBiDdHJHLw3L8NxF5IzAC7AQ+raqPZzQyY4zJkkyfjOPPkYiTHHwiXVzaz7h2k8LjACLiEZH3qeq3MhaZMcasUlOR2EIPocsZ81Y3iUi5iHxSRB4SkTeJ46PAReCdKxOiMcasLjNLErlsoZLEN4BBnIH9/hD4FM4Ngr+lqscyHJsxxmRFpqubrgwFE69zudEaFk4SW1V1H4CIfBnoBDap6mTGIzPGmFWofSDI27/wHPvcs++WmvQ7i+Ziw3U4/kJVoyLSYQnCGLOWqOqyNiz3jDqn0EM31FFf6qehonDBz6xbt47u7u5li2ExFkoS+0VkxH0tQJH7XgBV1fKMRmeMMavMVNhpj1hfWURjeWDB5e+66y5CoVBuJglV9a5UIMYYkyuSq3WWuyQx5TZapzuonyfLQ3bk7oAhxhizCk1FogB4vbndYB2XsSQhIl8VkR4ROZlivojI50TkvIicEJFbMhWLMcYs1XI3FsdLEt5FlE7iJZmcHSp8if4RuG+e+fcDO9yfB4EvZDAWY4zJCfE2iVx+ZGmyjCUJVX0KGJhnkQeAr6vjeZxxoRozFY8xxqRrZpvEcrLqpvRtANqT3ne404wxJmdkqrrJl2Z1U7bHdcqLhmsReVBEjojIkd7e3myHY4wxS5Zok1jr1U1puAJsTHrf5E6bRVW/pKoHVfVgXV3digRnjFm7MtlAPBWJIbK4JLFaG64X8gjwAbeX0x3AsKp2ZjEeY4yZJRNtEgW+vKjEARYxVPhiici3gUNArYh0AH+J82xsVPWLwKPAW4DzQBD4UKZiMcaYXDEVjhHwWpJAVd+zwHwFPpKp7RtjzHLIRMN1gT/9wSys4doYY3JMZtsknOqmbLQvLIUlCWOMmUdGShKLbJPIZmnCkoQxxqygqXCMAt/Sxk5da72bjDEm52Wkd5M/f069+ROpMcaskExesYeWUN2UTfkTqTHGZEFm2iS8aa/XejcZY8waMhWJEbCShDHG5K+V6AK7GGt1WA5jjMl5y17ddB29m7LBkoQxxqwg547r/Dn15k+kxhiTBRnpApsnDxwCSxLGGDPLUhNDOp9zGq6tuskYY1aF5SxJqOqS7pOwhmtjjFkDQlHnqXTWJmGMMavEYq7eF1o2/ujSfHqeRP5EaowxKyRT1TpT4XhJYnqbRLbvqp6PJQljjJnHUksSsViMX/7yl7S2tiamTUWiABT4picFSxLGGLPGxGJOqaGjoyMxLV7dNLPheqEkYQ3XxhiTQ5JPxsvaJhGvbvJadZMxxpgZEtVN1rvJGGPWtrlKFYneTYusbsomSxLGGDOPpVY3zfW54YkwAGUFvmnTLUkYY0weWY4G4rnW0TMyCUB9ecG06dZwbYwxeWo5G667RibxeoSaksUliWyyJGGMMRkwV8LoHpmivqwAr2f++yRqamoyGttiWJIwxph5LNeIsAPjIR4+2kF9eeGsZWcmifr6+iVtMxMsSRhjzAzLkRhmruMv/rUFgHt21GalbWGpLEkYY8w8lqsk0XJlmAduXs/H37Rz1rLpNlxnQ0aThIjcJyLnROS8iHxijvm/LyK9InLM/fnDTMZjjDGZFE8Mqe6RKA7M/bChdJNANkogvoUXWRoR8QKfB94IdACHReQRVT09Y9F/VtWPZioOY4xZrKUOy5FqHQBT4SgFKZ5It1Z7N90GnFfVi6oaAr4DPJDB7RlgcnKS0dHRbIdhTFZFo1H6+/sXXC4Wi9HX10cwGGR8fHzR24lEIgwMDCTeJ5ckZiWJSCyvhuOIy2TEG4D2pPcd7rSZ3i4iJ0TkYRHZONeKRORBETkiIkd6e3szEeuq8fzzz3P06NFsh2FMVl24cIGWlpYFL5gGBwc5efIkL774IocPH55zmflKEqdPn+bEiROEQqF5P6eqTpKwksSi/RBoVtWbgMeBf5prIVX9kqoeVNWDdXV1KxqgMSb/TExMABAOh+ddLhqNXtd2xsbGgNmJZK5SBFwbInzm/LXacH0FSC4ZNLnTElS1X1Wn3LdfBm7NYDzGmDUi3WEsUs1Pt01ivuSQ/DrVcyQWa7UNy3EY2CEiW0QkALwbeCR5ARFpTHr7NuBMBuMxxqwR15sk0jVfb6bpScIpsRT686+6KWO9m1Q1IiIfBX4CeIGvquopEfkMcERVHwH+o4i8DYgAA8DvZyoeY8za4fE417/xp8OlstxJIlXDdeJhQylKEmsySQCo6qPAozOmfTrp9SeBT2YyBmPM2pNuSWKhJLLQOuLzFlrPtYcNzV2SyGXZbrg2xqxic3UFXQnpJIn5Yks35nhyWKgkMRm+vobrbMpoScIYs7adO3eOrq4uDh06tKLbTSdJPPnkk2mtK52EsXCbhJMkltomYc+TMMasSl1dXVnZbvykmm4X10g0xlOv9NI5PLGk7aXbcH29vZuyIf8iNsaYBcSTRDptDgBXhiZ46fIgb3voWWDxw3Ks5oZrSxKrVD4NRWxWv5U+HhebJIbcZ0/3jk7RPhBc9PYW2r9rJYn86wJrSWKVsiRhckm2jsdUSWJmPENBJ0n4PMJnfnR6+UsS8ZvpbOwmkyssSZhcstLHY3x7qdokZsYzHAxRW1rAJ+7fxeOnu/nIt15iMpz+kB1zJaO5qpviDddLHZbDGq7NsrEkYXLJSh+P8ZN2uiWJqUiMIr+XD/1aM39+3y6uDk/wvZc6GAqGltS7aXZJYv6Ga6tuMisufoCOj49z6tSptOtmjcmETB5/XV1dXLp0adq0hW5ymzk9HI3h9woi8EeHtvHvXruVntEpWq4MpxVDfHvBUISfne5mdPLawILRaJTBq5cAnZUkcjk5xFmSWKXiB+2ZM2fo7e1d0lj5xiyXTJYkzp49u+gkMTOecFTxeT2J6W/Z10hxwEs4Eku7JPGn/3KcP/nOMU5eHebY5aHpN9ON9BPAHjpkcohVN5lckq02icWWJJKn+zwewtH0RoBVVR4+2nHts16ZNj8SU0TA7507GViSMMasadlKEqm2G4vFCEdjxNz5TpLwTPuc3yuEo6lLEqrKYy2dnO0aIRaLEfB62LGuBICJUHTa56IxpdDnmdUAvZjkICJZufizJLFKWUnC5JJcK0n0jk7yj89e4plX+wDnSj+5ugnA7/UQjqWOOxyJcq57lB+f7GI4GCIUjXFzUyVejxAMR6aXJKJKoS91QrCShFlxCz0py5iVlK3eTXNt9+SVYX7/qy8yHorQ1j9ONKZEY4rfI7OSRCSausF9dOJa4/Qr3c5jUiuL/RT4PEyEpnefdUoSsxNBPDlYkjArzpKEySW5VJJ4+GgH3cMTNFUV0T8e4ktPXQBYdHXTyMS151p/5oenAKgo8lPg886qborEYhSkaI/IdZYk8oSq0tPTk3ZXwpkHtnWBNXF9fX1EIpEV3eZCx18oFKK/v/+6tqGq9Pf3Ewpdu7dhdHQ08RzquLb+cW5YV8L9exvZt6EicTe0zytcvnw58d34vPM3XCcnCY/AvvoA1QVKod/DRHh2m0SRW5IYGxtjdNQpeVhJwiyboaEhTp8+zcWLF9Na3koSZi5TU1OcPHmS06dPr+h2Fzr+Tpw4QUtLy3VdzESjUVpaWmhpaZm2vQsXLkxb7mLfOBurCikp8HHPDXWJ6X6vh87OTvr6nHYKv2eBksTktSRR5Pfw728UwlOTFPi8XB0M8vkfPEvv6BTgtHkE3JLEkSNHOHXKKXksJklkK5HY8yTyRDjs1H9OTU2ltbyVJMxc4sfBxMTShsReqoWSRPxqPxKJEAgElrSNUCjE6GQYj2eckpKSxPT4/w7APzx1kbb+IG/ZUQ+M4/deu06Ov44v7/d6CM/bJuGUON5z2yZes28Xl9suAbCtrpSRqWEu9Y9zrnuU+/Y2EIkqBf7ZJ3m/3084HE7r//Puu+/OSqKwksQqZSUJM5dsHQfpbjf5hL6Y9QZDET76zcN85ZlWXrw0MG178XWqKt98oY2yAh9v278+Mb+hvBDgWnfYcBhVp7dTJJb66XWjbnVTgc+DJ+ncva+pgg/csYn33LYJgCuDE0RjSmCOS3Kfz5mYTvWfx+OxJGGuz3wjV1pJwkD2joN0k8Ri20ri6336lT6OtvYC0NIxTDhyrU0gvs72gQna+oP82f27qCnxJ9bxhl31lBb4aKxwksW1koQQjWmih9NQMMQ7v/gc/+n7LYQiMfrHJgFn+O+5vtfK4gAN5YUMBcOJhuuZ34Pf71/Sfq8kq25apawkYeaS7pPalsNih9uGxZ8so1EnGbQPBtm/YT331BfwwxNdfOaHp6gIKB+8s5migJMcT3eOALBvQwWq16pt68sL+cPXbp0VQ7z6KT4a7EuXB3nx0gAvXhrgm89fplSmuMEnBHyelPtXVRygbWCcYCjK5prZSTofkoSVJPLEYkeitJKEmUsmj4PJcJR/OdJOKDL7HoVMJYlYLMZgMMzYVIS7t1Swvb6M39y/nls3VzEZjtIz6lztH2nt5WvPtiICO9eVzfs9xEsSzrMfhLEpJ6bWPudhRB+7dwcBn4f79zbwtv3r8XpS3wldV1ZA0L1nom90alZ1Wj4kCStJXKf4wSYiRKPRWbfdh0IhPB4PE+EYBTPG9vJ6vYxNhima8SASv9+Px+NJfLagoCBxBRiNRgmFQogIfr9/2pVh8uv4UMXJn4vFYng8HiKRSKIuNBqNzqrrjEQiRKPRxP4EAoHEMpOTk4n3i6GqxGIxvN65BzhbSHLMyeuMRqP4fL7E/Jn7k7zMfHGpKj6fL/H3jH8HhYWFTExM4PP5Eg2qiS6SPt+079jr9SIis2JVVSYnJ/H7/ahq4m/g9/sJhUIUFhYmPhOJRBLrSRY/FuJisRjRaJSCggI8Hk8i7ngsyetTVbxeL4FAgGAwmIgpvh/x4wKceu/48vH1JX+fc8UZ38a/vtzJp753gv/+aAu15UVc7Avy+soB7t5Ry5bxcYqLiykqKmJ4Isz/+cPTxKJhCgM+qoq80DNAaYGP5uaJREyTk84JPhAIEAqFCAQCvNQ2wJeffJXPPLCXX54f5PArHUx0dSMC+9eXMTE8xfa6Eprryjl5uZe+sRCba0p46GdnOXFpkEM71uH3KKHQtZ5JM4VCIUKhEMUBLwoMB6eIRqNc6h2jqlB48Nc28P6DDUyNj3D+fGjaMTHTgU2VbKgq4tsvXmZ0PDirO+5i2iSyxZLEdTp+/DjDw8NUVlYyNDSUmD4UDNE5PEk0pkyGozx3sZ9dDWXUlRUmlhmZCHOsfYhbNldxx9ZqfClOvPv3708cXAMDA/zqV79CRDhw253803cfY3NNMeVFzgnobNcoFUV+9qnS2tqa6MVy4cIFOjs7ufHGGzl8+DC7d++mvr6ep59+msbGRnbu3AnA8PAwL7/88qwY1q9fT21tLSdOnKC+vp49e/Ys6ns6d+4cXV1dvO51r0NEGBsbw+v1UlRURH9/P1VVVYkTVTQaZXh4mEAggNfrpbe3l4sXL7J7926qqqqYmJggFovR0dFBf38/jY2NdHZ2UlFRwfDwMNu3b6epqQlwhpE+d+4ct99+e2Ik3Orq6sSJ+vTp0wwMDABw++23c/z4cSYnJxPj5JSXlzMyMoLH4+Gmm26iv7+f9vZ2ALZt28bw8HCiy6T4Cnipa4rxwT5CRdUMTcUYDkaITIwSiIzjFWH/pkr2baiY9t1s27aN1tZWmpqauHLlCl6vlwMHDjA+Pk5NTQ3Dw8McO3Zszu+1tLSULVu2cKLlJE+e6+bElVFisShetyU1GlN2N5bzmuZqqkuu9RqanJzkmWeeSZyAk5WUlLBlyxYmJydpa2ujurqa3bt3MzY2xpEjR6iurmZgYIC9e/dSUlLCT596jkKvcOwK7PZ2s6u8iEhsAC8TXBlSHmvpoqG8kNbWVkrKynnicoiWE2dpKFIisRjnwtfGUDpyaYB3HLqV0aE+6ouci6+JUJRgKEJZoZ8v/6qNUCjMf/1mG+2DQQSnTWB/UyVTowOJffARpSTgo2dkElVlvPsyb99YwK9vneKZZ56Ztr8zv4NgMEgwGKS4wLnKv3rlCk8/PczQxQ5uK45x+PDhWX+Hrq6uOf8+IsK68kLeuGcdtaUFnDx5ctr8goICAMrKytLuubjSLElcp+FhZ7z5oSFnaOATHcN0j0xytmuUmCpdsTIaPM6NM7/siDGuzhVDkYRZ507/wYUoJ8ZCNFQU8sDucryTI9O2cfz48VnbVVW+e+QyPz/bjUeEN9/YQIHfw09OdRHwenjT3crVq1enfSYYDCZOlH19fdTU1ADQ2dk5LUnEbd68mba2NgCuXr2a6FY482ooHfF/onhp4siRI4CTAFtaWti8eTNbtmwBnITS09Mzax39/f20tbUlrobjOjs7p8Xe09OTSBK9vU5jZmtra2Kdzc3NNDc3c/LkyWmJPRgMJq5e4yXBkZGRRNwzT9QXLlwgFInR1j/OsfYhrgw5CdnnEXzeYYr9XkoDXgoCXrzFxVzuH+PnZ3uJxKC8yM+WmiI8Iol+/JcvXwacJPnCCy8AsGvPHn7w3Bn6e/sI+DxUlwTYWleaiGFsbIyfPXuYn5zsYiAYormmhHWVxWhhBd29/RzvmuSxDh8vXu3kbbsr2N9UmfjsRCjKS23dNNeWJKpUCnwe6lWnncy6u7vZtm1b4oIjnlTHx8f5/E9P8fLp84lld9eX8idvv4fu7m5e6eihZ2SKJ8718IuzPdRWlPJyaytDE2G2VRby7ts2U1JSQnFxCX0Dgzze0k7LlWG+9OhzxBDq12+i1h/i0tUeJsNRaksLCIXCXI5VMdUzSoHEeNftW2gs8yf+RnG7du1i44UJzra201xbQjQ0SV1lTWK+iLBv3z6i0Sjl5eWJC4PCwsLEMbFuQvnWC+1MhKMcax+ifTDIzU2VNDc3U1xcPOe9JtXV1WzatClR8vF4PExNTXHzzf5EIoqX0lSV6upqSktLKSoqYmpqivPnzye+31xhSWKZhKMxznSO8MQ550RUXujnvW+4mb27buD44eco9HvZvmsPZRVVAIyNjXLq+DEK/B5ORxt59FQvT7QFudhzhX+/v5ACn5exqQiVxX6CU1EKA55ZJY2L3c4JrMjv5bGTnXjcKoFQNEYwtHDxdWb96FAwxH9+9AwjPVe4e0ctt9xSk0gScy2/FOFweFqVU/wfJ7nf/nzPvggGg04yvjJMQ3kh9WUFaXULjJ/84+sAEnfyNgZkAAAUGklEQVS9xqkq4WiM/rEQXo9QXuTD6xFncLakx07GSxmdw5P89FQXQ+4YPltrS7hpYyXvf+DN0+qoRQSfz8fA2BS/9fln+dypcZQYH35tLbcW9k7rqz/TV558lSeOXaLMM4UqRPCyZVsZv9EUocDnoeXKME++0osqvO6GOu7a3cRrDh5ExBn2umd0ir6xEH/z47N8/nQvBy9cIBiOEvB6KPB5GJ2K8NSrbq+gSCONnkF+Y1sBd26rZefOnXg8Hs6cOUM4HJ5WJaKqPH+hj8dPdvCahgrah8N4o5Pcf9tumpqamJiYoLFilLLiYp4410PLlWHGOyap9EW5d9c6ttSWcPDgQYqLixPf52vvupNjlwfpH53g8dO9HL48RNfUGPGUGI7GOHRDHf/h/b/FL351mN6+fg7uaqa6upqWlhaARAlZRHj97kbOtrbzk1NdiMDuTfVsb27k/PnziAjV1dWJ/Ylf0QPU19cDUOwmzsdPdyfmNVYWUVdXR0lJSSJJxO91AKirq6Oy8loiTkdpqbOHxcXFKatFsyn3IsozIxNhOgYneOrVXibDUcoL/dy4vpyDzdVs31BNU3UJ5wucr7m6rJgyt8hf5CmmKOCceD5y704++uu7eO5CP3/0lSf4yjOdifWLgCrUlATYs76cvRsqEg8uudI/xLryQn7nlg0cuzzkJocoZzpH+JvHzrLRO4TGohQHvOzbUJFoN4lLPukPjIe47388BeODrPdE+MmpLs5Ez7K/YIxt7pVr/CRxPfWn8frrpRqZDHP66gjPX3SGcCgJ+Di0s47t9aXzJot0Yh6fDPHPL7bTN+4U+0XAI043yJuanEbRo22DDAdDicRQ4PPwuhvq2FpXSkWRc0U7V5sCQHVpAY9//HUMBcP8zY/P8cWn29jv6yTgFfxe4Z4ddexqLAdIlEq/dzrE/VsrOLStnGdf7aNjJMzPzw3QfqE3sd7a0gJ+86b1VBT78Sa1H3g8HhoqimioKOKz7z7Af/3pOS6ecE54oWiMhopCbtxQQftAkIaKQj7xhjv5l6eO8+LFC7zaM8bBqSru3lHrLO/W018ZmuBE+xCdw5NcnipkW00hv/uaJvwBP8PDQ2xvdC6C4g2yDVUl7F1fwbb6UnZvbmRkeIiA+3S2QCAw647jA5udE/ev790AOKWrmaMMeD3ChupS/JEgPp9v2kVHQcG1i4atdSX84Wu38uyrfTTXlrCptmxRN+qVBLx4cEonexrLqSwOsK2uJLFviXi83sT/0lLb3HJZRpOEiNwHfBbwAl9W1f93xvwC4OvArUA/8C5VvZTJmJbTj05c5avPtgLOuC9v2tPAtvqSxEl85lVB8sGV/Dp+UN+5rYbPvfcgf/+9XxBTZc/6cl6+PERRwClVPP1qHyc6hikt8BEMRWkZLeLe9c6AYrdvdYrSPaOTnOkc4ZnzfWz0DuF1D/LGiiLqygqmJYb4iVNV+bOHjzMUDPOZe7dTGRvm52e6+e7Jbi77Onng5vVsqS1NfDZ+ol/KjT0zr0jnKp0cbx9iZGyMmzdW4hEhEo3RcmWYwbZJWs5fRhXqywrYXFPC6asj/FtLJ9vqSrl3dz3Fc92xBHM2VHYOT3Cuc5jt9aU8f6GfthdHYHyK1++sJ+Dz8Pi5AXxE2NZQxYmOAU50TH+Upd/r4X23b6a8aPpJY77vpcDnZV25l//7t/dy6+Yqrr4SIzgxRfvQFD87003XyCQx8TI8NkHbQJAddY28cVcVPo/wup31BAIBfrekia99/3GqSwLsWFfG3g3liVJmqm1XlQT4f357Hz8u7aF3dAoRaKoqBuAO99i5Y1stDf5dfD08wKX+cT73RCsP/bKV32qa5LEOLyMjo3RevfZgnSJfAR+8YyNFhX6ntOTxJI7r+G8R4df3rAOguMDHZNLjO9O5ap55Qp75Hfv9/mn7nLy8qlJa4OPNexsS21vMlbqI0FRVREWhnzfe2JAy7uTtL7ZDRz7IWJIQES/weeCNQAdwWEQeUdXkirw/AAZVdbuIvBv4L8C7MhXTcvnVhT4+9p1j9I5OcmtAKAn4eNON6xL/dHEzD/Dk96muOG7dUseH7m4GdQYYu21LNQG3OuKV7jFOXhkmpspgMESBBNizfnojaE1JATeuL+f/uPtmdKSL/tEJvvZsK6euDnNTUwW957uZHApSXR0jHA4zGAxxsXecn50J8um37uGW+jBXr47xGzet5zMfvpv/8N+/xQ+OXeWWTVXsmPQhU5M0VBQuqqdSKBLj6tAE5UV+hsYmuDoaZmA8RGWRn6mpKUKRGNFojPM9o/xf/3aGrvMdFEqYI5cG8Yoz7s1EOMqwFnFDRSH37KijsaIQj0e4ZVMVT77Sw9muUUKRGK/bWUdpqdLaN86nf3CSYOdFagNhbmuu5lcX+ugfDzGk7XR7LrNDO/AQ42jbIEV+L3XVwt719Yl6+1t2NDE4OEhdTTX//EyY6tIAN64vd0+IgiqJ0uBiFfq9vPf2TbwoXQSDQTyBYr7x1BnOdI4w5SmkVEIc2FjFOw/tpLvzKsWlTqO8iPD6PY1I3xZ8Hll0oi70e9lYXZxyfmlxAffcUMed0RreWbuDrz3byoWeVxga7KdQQhzYWMmBTVV4RaipqcJHDL/fn0j88Sv15CQRN7MEmU7s8fXEe1TN5PV6p52YZyaJmetKlXRSecetG2dNm5kIkt/n8kB9S5XJksRtwHlVvQggIt8BHgCSk8QDwF+5rx8GHhIR0Ry986treJKv/aqVh490UF7k5/23bWeXFKX93Np0Dia/3z+t7SF53TsbytjZUAbAxd4xdmxqJDoxvV7d6xHeuKeBbfWlnB+B8kIflUV+jrUPcax9iBHtplwmeaFjgqraAVpOXwLg9Ttv5kN3NXPmzJnEuooCPh44sJ6fnurmpcuDPN02TomEePONDdzpdoGcy3AwzD88fTHRGHr40gD+HqdHUPsvB5jExw5vH+vKCtnQMcWxV9sJ0sHZsNP+8f6tVdQWamJwNIBwTNlQX8P+ddOrC4oCXu7b28jG6mIeP93NN59vo656iCf/tYdwLMY7m4tp7ezlhyeuNeL7iPH+OzZBV5Aiv1OdtL2+lG1NDdMaDctLipgYG6G0pJi33NQ4575er/hVaX11Oe+7YzNAorcWQCTkfAfFxcWJhnmfz5eyHeN6T1KJkoDXw737NvCmfRt46qkYzc3NjI2NJXpyAQQ8MDUVpry8PHECjx8Ty1XtEv+fiSeiufZvMUkiE3X+8yXC1SCTSWID0J70vgO4PdUyqhoRkWGgBuhjmT129DzffvzF61rHeCjCRCjKrpIA7z2widrSYSYmUv8zzDyg0/kHTvcg3lpXik6lbuC9ePFi4p/qna/ZSMfgBIdbB3hgey0dg+O0XBmia8Bp+K4uDvB72yMcPnx4Vje88qIAv3PLBvrGQijw5Cu9/PxMN8/93cPA3PszEY4yNuU0rAIUeT382o46Wq4MUxKb5J6d9YyO1/JC6wBdr7QjKIVM8eE9yq6GMqoK5v5nS74fYKYb11cwMB7iaNsgQ8NjvLYqxm/etIGqAmVgYxHdI5OUF/rxeYXSwgC1FWMES6qnrSO5pxMwq+okE+LHRHHxtav75NeDg4MAFBY6Xad9Pt+8x9H1ngSTPx8/+fp8Pjo6Omb9TcbGxpznLiQ13Ca3hySvz+v1LilxxNcXv18l/reIr2vmPT7zVf34fL5pJZOlSF5n/HicLzEtdf25VCLJi4ZrEXkQeBBg06ZNS1pHWVGAmsqy64qjFuG1N9Ryw7pr6ykrK0NVKStz7uIMBq81psW7mN58881zjrq5e/fuWScgj8eT6G7Y0NDA+Ph44uo2XrQuKSkhHA4zPj6e6DmTLLlxOH7D1+YNUe7etw1V5XYRfmdG75v48iUlJXi93kTPj1tvvZUrV66wzh3+YO+Ne/jGL08yuUDvqYPN1dy88VovDxHhzQd1WlvG/a8R90YuIRZTPJ7p/+zxZZPvn4hPLywspLi4mNHRUVSVmpoa9u/30tPTM6taoq5OuGHGDWLg9CrxeDx4PJ7EzYbx9VdWVlJWVkYoFKK+3mkLGBkZIRAIUFFRQX9/fyK+uro6xsbG8Pv9007w6di8eTPd3d3U19cnhpiIry9+Q6TH46GxsRFVZd06p37/hhtuoKCgYNYzGDZv3jzv9g4cOEB3dzfFxcVEo1HC4TClpaWJ3j3FxcWsX7+eoqKiaeuMdwWura1lbGyMiooKuru7EZHE91NcXJzo2VNZWcmmTZtoamqiq6uLmpqaxPdTWlqadsKYaz0AW7Zswev1UldXh4jMihlg69ateL1eysrK6O/vp7KyEp/Px9atW6mtrU1r+9u2bWN0dDRxk2Fyj6hbb72V/v5+1q1bR1tb27T/+aXatm0bgUCAuro69u/fP+9NfytFMlU8EpE7gb9S1Te77z8JoKr/OWmZn7jLPCciPqALqJuvuungwYMa72NvjDEmPSJyVFUPLvZzmWyKPwzsEJEtIhIA3g08MmOZR4APuq/fAfwiV9sjjDFmLcpYdZPbxvBR4Cc4XWC/qqqnROQzwBFVfQT4CvANETkPDOAkEmOMMTkio20Sqvoo8OiMaZ9Oej0J/G4mYzDGGLN0q+/OD2OMMcvGkoQxxpiULEkYY4xJyZKEMcaYlCxJGGOMSSljN9Nlioj0Am0LLji3WjIw5EeW2T7lB9un/LCa92mzqtYt9sN5lySuh4gcWcodh7nM9ik/2D7lB9un2ay6yRhjTEqWJIwxxqS01pLEl7IdQAbYPuUH26f8YPs0w5pqkzDGGLM4a60kYYwxZhHWTJIQkftE5JyInBeRT2Q7nnSJyFdFpEdETiZNqxaRx0XkVfd3lTtdRORz7j6eEJFbshd5aiKyUUSeEJHTInJKRD7mTs/b/RKRQhF5UUSOu/v01+70LSLyghv7P7vD5iMiBe778+785mzGn4qIeEXkZRH5kfs+3/fnkoi0iMgxETniTsvb4w5ARCpF5GEROSsiZ0TkzuXcpzWRJETEC3weuB/YA7xHRPZkN6q0/SNw34xpnwB+rqo7gJ+778HZvx3uz4PAF1YoxsWKAB9X1T3AHcBH3L9HPu/XFPAGVd0P3AzcJyJ3AP8F+DtV3Q4MAn/gLv8HwKA7/e/c5XLRx4AzSe/zfX8AXq+qNyd1C83n4w7gs8CPVXUXsB/n77V8+xR/ROJq/gHuBH6S9P6TwCezHdci4m8GTia9Pwc0uq8bgXPu678H3jPXcrn8A/wAeONq2S+gGHgJ55nufYDPnZ44DnGes3Kn+9rnLifZjn3GfjS5J5g3AD/Ceah53u6PG9sloHbGtLw97oAKoHXmd72c+7QmShLABqA96X2HOy1frVPVTvd1F7DOfZ13++lWSxwAXiDP98utmjkG9ACPAxeAIVWNP3Q7Oe7EPrnzh4Hre0Dy8vsfwJ8BMfd9Dfm9PwAK/FREjorIg+60fD7utgC9wNfcasEvi0gJy7hPayVJrFrqXA7kZRc1ESkFvgv8saqOJM/Lx/1S1aiq3oxzBX4bsCvLIS2ZiLwV6FHVo9mOZZndraq34FS7fERE7kmemYfHnQ+4BfiCqh4AxrlWtQRc/z6tlSRxBdiY9L7JnZavukWkEcD93eNOz5v9FBE/ToL4lqp+z52c9/sFoKpDwBM41TGVIhJ/AmRy3Il9cudXAP0rHOp87gLeJiKXgO/gVDl9lvzdHwBU9Yr7uwf4V5xkns/HXQfQoaovuO8fxkkay7ZPayVJHAZ2uD0zAjjP0n4kyzFdj0eAD7qvP4hTpx+f/gG3B8MdwHBSkTNniIjgPN/8jKr+bdKsvN0vEakTkUr3dRFOG8sZnGTxDnexmfsU39d3AL9wr/hygqp+UlWbVLUZ5//lF6r6PvJ0fwBEpEREyuKvgTcBJ8nj405Vu4B2EdnpTroXOM1y7lO2G15WsIHnLcArOPXEf5HteBYR97eBTiCMc9XwBzh1vT8HXgV+BlS7ywpOL64LQAtwMNvxp9inu3GKvyeAY+7PW/J5v4CbgJfdfToJfNqdvhV4ETgP/AtQ4E4vdN+fd+dvzfY+zLNvh4Af5fv+uLEfd39Oxc8D+XzcuXHeDBxxj73vA1XLuU92x7UxxpiU1kp1kzHGmCWwJGGMMSYlSxLGGGNSsiRhjDEmJUsSxhhjUrIkYdY8EYm6o4LGf+YdJVhEPiwiH1iG7V4SkdrrXY8xmWRdYM2aJyJjqlqahe1ewumn3rfS2zYmXVaSMCYF90r/b9znD7woItvd6X8lIn/qvv6P4jwX44SIfMedVi0i33enPS8iN7nTa0Tkp+I8b+LLODc2xbf1fncbx0Tk793h7Y3JOksSxkDRjOqmdyXNG1bVfcBDOKOizvQJ4ICq3gR82J3218DL7rRPAV93p/8l8Iyq3ogzbtAmABHZDbwLuEudAQKjwPuWdxeNWRrfwosYs+pNuCfnuXw76fffzTH/BPAtEfk+zpAI4Aw78nYAVf2FW4IoB+4Bfsed/m8iMugufy9wK3DYGdaKIq4NyGZMVlmSMGZ+muJ13G/gnPx/E/gLEdm3hG0I8E+q+sklfNaYjLLqJmPm966k388lzxARD7BRVZ8A/hxneOxS4Gnc6iIROQT0qfO8jKeA97rT78cZiA2cgdjeISL17rxqEdmcwX0yJm1WkjDGbZNIev9jVY13g60SkRM4z7B+z4zPeYFvikgFTmngc6o6JCJ/BXzV/VyQa0M2/zXwbRE5BfwKuAygqqdF5D/hPDHNgzPi70eAtuXeUWMWy7rAGpOCdVE1xqqbjDHGzMNKEsYYY1KykoQxxpiULEkYY4xJyZKEMcaYlCxJGGOMScmShDHGmJQsSRhjjEnp/weO0vKqhcLPzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 0:20:51.439946\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "\n",
    "from ddpg import DDPG\n",
    "\n",
    "NUM_EPISODES = 3000\n",
    "SOLVED_IN= 0.5\n",
    "\n",
    "start= datetime.now()\n",
    "\n",
    "states, num_agents= env_reset(env, True)\n",
    "\n",
    "# Hyperparameters\n",
    "config= {\n",
    "    \"label\": \"Noisy layerNorm copy\",\n",
    "    \"state_size\": states.shape[1],\n",
    "    \"action_size\": brain.vector_action_space_size,\n",
    "    \"seed\": seed,\n",
    "    \"actor_lr\": 1e-3,\n",
    "    \"critic_lr\": 1e-3,\n",
    "    \"actor_nodes\": [32, 32],\n",
    "    \"critic_nodes\": [128, 128],\n",
    "    \"batch_size\": 256,\n",
    "    \"memory_size\": 100000,\n",
    "    \"discount\": 0.9,\n",
    "    \"tau\": 0.001,\n",
    "    \"action_noise\": \"No\",    # Options: No, Normal, OU, \n",
    "    \"sigma\": 0.1,            # OUNoise, Normal\n",
    "    #\"param_noise\": True,\n",
    "    #\"noise_scale\": 0.3,      # initial noise scale for param noise (default: 0.3)\n",
    "    \"critic_l2_reg\": 0.0,  # 1e-2\n",
    "}\n",
    "\n",
    "\n",
    "scores_window = deque(maxlen=100)\n",
    "                     \n",
    "agents= Agents(num_agents, config= config)\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "    states, _= env_reset(env, True)\n",
    "    agents.reset()\n",
    "    score = np.zeros(num_agents)\n",
    "    \n",
    "    while True:\n",
    "        actions= agents.act(states)    # Agent action. Include noise\n",
    "        next_states, rewards, dones= env_step(env, actions)   # Environmet step\n",
    "        # Agent step. Includes learnig from memory\n",
    "        agents.step(states, actions, rewards, next_states, dones)\n",
    "        \n",
    "        score+= rewards        # update the score\n",
    "        states= next_states     # roll over the state to next time step\n",
    "        if np.any(dones):              # exit loop if episode finished\n",
    "            break\n",
    "    \n",
    "    \n",
    "    max= np.max(score)\n",
    "    agents.update(max)          # Add score to agents and update param noise\n",
    "    scores_window.append(max)       \n",
    "    mean_w_scores= np.mean(scores_window)\n",
    "    print('\\rEpisode {}\\tAverage Score: {:.2f}   '.format(episode+ 1, mean_w_scores), end=\"\")\n",
    "    if (episode+ 1) % 100 == 0:\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}   '.format(episode+ 1, mean_w_scores))\n",
    "    if mean_w_scores >= SOLVED_IN:\n",
    "        print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format((episode+ 1)-100, mean_w_scores))\n",
    "        break\n",
    "    \n",
    "        \n",
    "agents.save()\n",
    "\n",
    "\n",
    "        \n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N \n",
    "\n",
    "smoothed_scores= running_mean(agents.scores, 10)\n",
    "plt.plot(np.arange(len(smoothed_scores)), smoothed_scores)\n",
    "plt.plot(np.arange(len(agents.scores)), agents.scores, color='grey', alpha=0.5)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print('Elapsed time', datetime.now()- start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.- See how the agent behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Actor:\n\tWhile copying the parameter named \"model.1.bias_sigma\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.1.bias_epsilon\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.1.bias_mu\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.1.weight_epsilon\", whose dimensions in the model are torch.Size([128, 24]) and whose dimensions in the checkpoint are torch.Size([32, 24]).\n\tWhile copying the parameter named \"model.1.weight_sigma\", whose dimensions in the model are torch.Size([128, 24]) and whose dimensions in the checkpoint are torch.Size([32, 24]).\n\tWhile copying the parameter named \"model.1.weight_mu\", whose dimensions in the model are torch.Size([128, 24]) and whose dimensions in the checkpoint are torch.Size([32, 24]).\n\tWhile copying the parameter named \"model.3.running_mean\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.3.running_var\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.3.weight\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.3.bias\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.4.bias_sigma\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.4.bias_epsilon\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.4.bias_mu\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.4.weight_epsilon\", whose dimensions in the model are torch.Size([128, 128]) and whose dimensions in the checkpoint are torch.Size([32, 32]).\n\tWhile copying the parameter named \"model.4.weight_sigma\", whose dimensions in the model are torch.Size([128, 128]) and whose dimensions in the checkpoint are torch.Size([32, 32]).\n\tWhile copying the parameter named \"model.4.weight_mu\", whose dimensions in the model are torch.Size([128, 128]) and whose dimensions in the checkpoint are torch.Size([32, 32]).\n\tWhile copying the parameter named \"model.6.running_mean\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.6.running_var\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.6.weight\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.6.bias\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.7.weight_epsilon\", whose dimensions in the model are torch.Size([2, 128]) and whose dimensions in the checkpoint are torch.Size([2, 32]).\n\tWhile copying the parameter named \"model.7.weight_sigma\", whose dimensions in the model are torch.Size([2, 128]) and whose dimensions in the checkpoint are torch.Size([2, 32]).\n\tWhile copying the parameter named \"model.7.weight_mu\", whose dimensions in the model are torch.Size([2, 128]) and whose dimensions in the checkpoint are torch.Size([2, 32]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-91e452bc75c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mAgents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d1e3c924e33a>\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"last_actor_{}.pth\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/drlnd/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 721\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Actor:\n\tWhile copying the parameter named \"model.1.bias_sigma\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.1.bias_epsilon\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.1.bias_mu\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.1.weight_epsilon\", whose dimensions in the model are torch.Size([128, 24]) and whose dimensions in the checkpoint are torch.Size([32, 24]).\n\tWhile copying the parameter named \"model.1.weight_sigma\", whose dimensions in the model are torch.Size([128, 24]) and whose dimensions in the checkpoint are torch.Size([32, 24]).\n\tWhile copying the parameter named \"model.1.weight_mu\", whose dimensions in the model are torch.Size([128, 24]) and whose dimensions in the checkpoint are torch.Size([32, 24]).\n\tWhile copying the parameter named \"model.3.running_mean\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.3.running_var\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.3.weight\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.3.bias\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.4.bias_sigma\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.4.bias_epsilon\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.4.bias_mu\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.4.weight_epsilon\", whose dimensions in the model are torch.Size([128, 128]) and whose dimensions in the checkpoint are torch.Size([32, 32]).\n\tWhile copying the parameter named \"model.4.weight_sigma\", whose dimensions in the model are torch.Size([128, 128]) and whose dimensions in the checkpoint are torch.Size([32, 32]).\n\tWhile copying the parameter named \"model.4.weight_mu\", whose dimensions in the model are torch.Size([128, 128]) and whose dimensions in the checkpoint are torch.Size([32, 32]).\n\tWhile copying the parameter named \"model.6.running_mean\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.6.running_var\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.6.weight\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.6.bias\", whose dimensions in the model are torch.Size([128]) and whose dimensions in the checkpoint are torch.Size([32]).\n\tWhile copying the parameter named \"model.7.weight_epsilon\", whose dimensions in the model are torch.Size([2, 128]) and whose dimensions in the checkpoint are torch.Size([2, 32]).\n\tWhile copying the parameter named \"model.7.weight_sigma\", whose dimensions in the model are torch.Size([2, 128]) and whose dimensions in the checkpoint are torch.Size([2, 32]).\n\tWhile copying the parameter named \"model.7.weight_mu\", whose dimensions in the model are torch.Size([2, 128]) and whose dimensions in the checkpoint are torch.Size([2, 32])."
     ]
    }
   ],
   "source": [
    "states, num_agents= env_reset(env, False)\n",
    "\n",
    "config= {\n",
    "    \"label\": \"Noise\",\n",
    "    \"state_size\": states.shape[1],\n",
    "    \"action_size\": brain.vector_action_space_size,\n",
    "    \"seed\": seed,\n",
    "    \"actor_lr\": 0.001,\n",
    "    \"critic_lr\": 0.001,\n",
    "    \"actor_nodes\": [128, 128],\n",
    "    \"critic_nodes\": [128, 128],\n",
    "    \"batch_size\": 512,\n",
    "    \"memory_size\": 100000,\n",
    "    \"discount\": 0.9,\n",
    "    \"sigma\": 0.1, # OUNoise\n",
    "    \"tau\": 0.001,\n",
    "}\n",
    "\n",
    "agents= Agents(num_agents, config= config)\n",
    "\n",
    "agents.load()\n",
    "agents.eval()\n",
    "\n",
    "score = np.zeros(num_agents)                       # initialize the score\n",
    "while True:\n",
    "    #print(type(states), states)\n",
    "    actions= agents.act(states, False)\n",
    "    #agents.eval()\n",
    "    next_states, rewards, dones= env_step(env, actions)\n",
    "    score += rewards                                # update the score\n",
    "    states= next_states   \n",
    "    if np.any(dones):                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"\\rFinal score: {:.1f}\".format(np.max(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "files= glob(\"*.data\")\n",
    "\n",
    "for file in sorted(glob(\"*.data\")):\n",
    "    data= torch.load(file)\n",
    "    scores= data[\"scores\"]\n",
    "    smoothed_scores= running_mean(scores, 10)\n",
    "    # Label\n",
    "    # Label\n",
    "    label= \"Critic lr: \"\n",
    "    if \"label\" in data[\"config\"]:\n",
    "        label= \"Sigma: {}\".format(data[\"config\"][\"sigma\"])\n",
    "    plt.plot(np.arange(len(smoothed_scores)), smoothed_scores, label= label)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.2)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print models\n",
    "print(agents.agents[0].actor)\n",
    "print(agents.agents[0].critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
